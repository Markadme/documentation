{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"general/Guidelines/","text":"Guidelines Project Structure project \u2502 README.md | \u2514\u2500\u2500 doc \u2514\u2500\u2500 src | | __init__.py | | \u2502 \u2514\u2500\u2500 nodes | | __init__.py | | \u2502 \u2514\u2500\u2500 data_sources | | | __init__.py | | \u2502 \u2514\u2500\u2500 data_processors | | | __init__.py | | \u2502 \u2514\u2500\u2500 end_nodes | | __init__.py \u2502 \u2514\u2500\u2500 scripts \u2514\u2500\u2500 launch \u2514\u2500\u2500 (windows_scripts) \u2514\u2500\u2500 testing doc contains all files related to the documentation (Readme) src contains the actual project files. Everything in this folder is declared to a package by the __init__.py to allow a uniform import src/nodes Contains all modules that can be connected through the framework src/nodes/data_sources Contains all data sources src/nodes/data_processors Contains all data processors src/nodes/end_nodes Contains all end nodes scripts Contains all scripts that can be executed with ros launch Contains all launch scripts for ros windows_scripts Contains all scripts that can be executed in windows without ros testing Contains all testcases Naming Classes and files with classes are named in CamelCase files with classes will be named like the class files that consist only of methods are named in snake_case variables are named in snake_case methods are named in CamelCase Git guidelines ? Testing ?","title":"Guidelines"},{"location":"general/Guidelines/#guidelines","text":"","title":"Guidelines"},{"location":"general/Guidelines/#project-structure","text":"project \u2502 README.md | \u2514\u2500\u2500 doc \u2514\u2500\u2500 src | | __init__.py | | \u2502 \u2514\u2500\u2500 nodes | | __init__.py | | \u2502 \u2514\u2500\u2500 data_sources | | | __init__.py | | \u2502 \u2514\u2500\u2500 data_processors | | | __init__.py | | \u2502 \u2514\u2500\u2500 end_nodes | | __init__.py \u2502 \u2514\u2500\u2500 scripts \u2514\u2500\u2500 launch \u2514\u2500\u2500 (windows_scripts) \u2514\u2500\u2500 testing doc contains all files related to the documentation (Readme) src contains the actual project files. Everything in this folder is declared to a package by the __init__.py to allow a uniform import src/nodes Contains all modules that can be connected through the framework src/nodes/data_sources Contains all data sources src/nodes/data_processors Contains all data processors src/nodes/end_nodes Contains all end nodes scripts Contains all scripts that can be executed with ros launch Contains all launch scripts for ros windows_scripts Contains all scripts that can be executed in windows without ros testing Contains all testcases","title":"Project Structure"},{"location":"general/Guidelines/#naming","text":"Classes and files with classes are named in CamelCase files with classes will be named like the class files that consist only of methods are named in snake_case variables are named in snake_case methods are named in CamelCase","title":"Naming"},{"location":"general/Guidelines/#git-guidelines","text":"?","title":"Git guidelines"},{"location":"general/Guidelines/#testing","text":"?","title":"Testing"},{"location":"general/interaction-of-the-projects/","text":"Interaction of the projects \u2139 INFO: The solid boxes are projects that are also explained in this documentation.","title":"Interaction of the projects"},{"location":"general/interaction-of-the-projects/#interaction-of-the-projects","text":"\u2139 INFO: The solid boxes are projects that are also explained in this documentation.","title":"Interaction of the projects"},{"location":"general/framework/architecture/","text":"Architecture Targets The primary goals of the framework are: a unified project structure multithreading security compatibility Ensuring customizability Objects and Classes Basic datastream Standard call sequences Registration Pipeline call","title":"Architecture"},{"location":"general/framework/architecture/#architecture","text":"","title":"Architecture"},{"location":"general/framework/architecture/#targets","text":"The primary goals of the framework are: a unified project structure multithreading security compatibility Ensuring customizability","title":"Targets"},{"location":"general/framework/architecture/#objects-and-classes","text":"","title":"Objects and Classes"},{"location":"general/framework/architecture/#basic-datastream","text":"","title":"Basic datastream"},{"location":"general/framework/architecture/#standard-call-sequences","text":"","title":"Standard call sequences"},{"location":"general/framework/architecture/#registration","text":"","title":"Registration"},{"location":"general/framework/architecture/#pipeline-call","text":"","title":"Pipeline call"},{"location":"general/framework/getting-started/","text":"Getting started Installation download https://github.com/mfr-driverless/driverless-framework/releases/tag/v0.2.3 execute pip install <path to zip>/driverless_framework-0.2.3.tar.gz NOTE: The framework must be installed on the windows computer as well as in the WSL. Project creation The following steps should be created Data Enum from driverless_framework.architecture.basic_objects import IDataID import enum class DataID(IDataID): TEST_DATA = 1 TEST_DATA2 = 1 Nodes Data sources from <path to id enum>.DataID import DataID from driverless_framework.architecture.basic_objects import IDataSource from driverless_framework.architecture.data_structure import DataGroup from driverless_framework.architecture.data_structure import DataField class Source(IDataSource): def __init__(self): super().__init__() self.__registeredMethods = [] def getName(self): return \"Source\" def registerMethod(self, dataID): print(\"Register: \"+str(dataID)) self.__registeredMethods.append(dataID) def start(self): while True: if DataID.TEST_DATA in self.__registeredMethods: test_data = ... # Get required data self._insertData(DataID.TEST_DATA, DataField(test_data)) if len(self.__registeredMethods) > 0: print(\"Data collected...\") self._callUpdate() \u2139 INFO: This is a standard implementation that should be adapted to the use case. It is important that the methods are present! registerMethod() wird vor start des Managers aufgerufen. Hier werden der Source die angefragten IDs \u00fcbergeben, welche wenn m\u00f6glich bereitgestellt werden sollten start() is called once at startup. With _insertData() datasets can be provided. They are pushed into the pipeline by executing _callUpdate() . In _insertData() records must be encapsulated in a DataField object. The data length of the entire data can also be passed here. However, this is usually only used for recorded data, since otherwise this information is not yet known at runtime. Data processors from driverless_framework.architecture.node_types import DataProcessor from driverless_framework.architecture.decorators.node_decorator import node from <path to id enum>.DataID import DataID class Processor(DataProcessor): def getName(self): return \"Processor\" @node([DataID.TEST_DATA, DataID.TEST_DATA2]) # requests datasets def receive(self, data): test_data = data.getData(DataID.TEST_DATA).data # gets requested data test_data2 = data.getData(DataID.TEST_DATA2).data self._publish(DataID.TEST_DATA3, ...) # pipes calculated data to next nodes \u2139 INFO: it is recommended not to use an already existing id in the publish method, otherwise the following nodes can no longer access the original dataset! End nodes from driverless_framework.architecture.node_types import EndNode from driverless_framework.architecture.decorators.node_decorator import node from <path to id enum>.DataID import DataID class ENode(EndNode): def getName(self): return \"ENode\" @node([DataID.TEST_DATA]) # requests datasets def receive(self, data): test_data = data.getData(DataID.TEST_DATA).data # gets requested data \u2139 INFO: an endNode is comparable to a dataprocessor, except that you can't publish (pass on) data. Manager import driverless_framework.architecture as a # Source(), EndNode() and Processor() has to be replaced manager = a.ManagerBuilder(Source(), EndNode()) \\ .addProcessorNode(Processor()) \\ .build() manager.start() \u2139 INFO: The manager merges the notes into a pipeline and executes it. The further behavior is primarily regulated in the source node. Special functions Data recording import driverless_framework.architecture as a import driverless_framework.architecture.basic_nodes as b manager = a.ManagerBuilder(b.Player(\"<path>\", loop=True), b.Recorder(\"<path>\")) \\ .addProcessorNode(Processor()) \\ .build() manager.start() loop means that when the end of the recording is reached, it is played again from the beginning. Global variables self._publish(DataID.TEST_DATA3, ..., globalVariable=True) \u2139 INFO: Global variables are multithreading safe for calling in ros. The last value entered is always used. This allows data from nodes further down the pipeline to be sent to nodes further up the pipeline, which can retrieve the data like a normal dataset on the next pipeline run. Global variables are declared via an extra enum that inherits from IGlobalDataID. ALL DataID It is possible by importing the BasicDataID enum and specifying it in the node anotation ( BasicDataID.ALL ) to get all datasets that have already been requested by a previous node. This is mainly intended for recording the data or a possible publication in the ros bridge. Usually this is only used in an EndNode. Testing The framework offers a testcontainer for testing purposes. Here a processor node can be called like a normal function. The method expects a DataGroup with all required data sets as attribute. The output is also a DataGroup. group = DataGroup(0) group.addData(DataID.TEST_DATA, DataField(<data>)) group.addData(DataID.TEST_DATA2, DataField(<data>)) output = TestContainer(Processor()).test(group) # Processor is the Node to test out_data = output.getData(DataID.TEST_DATA3).data","title":"Getting started"},{"location":"general/framework/getting-started/#getting-started","text":"","title":"Getting started"},{"location":"general/framework/getting-started/#installation","text":"download https://github.com/mfr-driverless/driverless-framework/releases/tag/v0.2.3 execute pip install <path to zip>/driverless_framework-0.2.3.tar.gz NOTE: The framework must be installed on the windows computer as well as in the WSL.","title":"Installation"},{"location":"general/framework/getting-started/#project-creation","text":"The following steps should be created","title":"Project creation"},{"location":"general/framework/getting-started/#data-enum","text":"from driverless_framework.architecture.basic_objects import IDataID import enum class DataID(IDataID): TEST_DATA = 1 TEST_DATA2 = 1","title":"Data Enum"},{"location":"general/framework/getting-started/#nodes","text":"","title":"Nodes"},{"location":"general/framework/getting-started/#data-sources","text":"from <path to id enum>.DataID import DataID from driverless_framework.architecture.basic_objects import IDataSource from driverless_framework.architecture.data_structure import DataGroup from driverless_framework.architecture.data_structure import DataField class Source(IDataSource): def __init__(self): super().__init__() self.__registeredMethods = [] def getName(self): return \"Source\" def registerMethod(self, dataID): print(\"Register: \"+str(dataID)) self.__registeredMethods.append(dataID) def start(self): while True: if DataID.TEST_DATA in self.__registeredMethods: test_data = ... # Get required data self._insertData(DataID.TEST_DATA, DataField(test_data)) if len(self.__registeredMethods) > 0: print(\"Data collected...\") self._callUpdate() \u2139 INFO: This is a standard implementation that should be adapted to the use case. It is important that the methods are present! registerMethod() wird vor start des Managers aufgerufen. Hier werden der Source die angefragten IDs \u00fcbergeben, welche wenn m\u00f6glich bereitgestellt werden sollten start() is called once at startup. With _insertData() datasets can be provided. They are pushed into the pipeline by executing _callUpdate() . In _insertData() records must be encapsulated in a DataField object. The data length of the entire data can also be passed here. However, this is usually only used for recorded data, since otherwise this information is not yet known at runtime.","title":"Data sources"},{"location":"general/framework/getting-started/#data-processors","text":"from driverless_framework.architecture.node_types import DataProcessor from driverless_framework.architecture.decorators.node_decorator import node from <path to id enum>.DataID import DataID class Processor(DataProcessor): def getName(self): return \"Processor\" @node([DataID.TEST_DATA, DataID.TEST_DATA2]) # requests datasets def receive(self, data): test_data = data.getData(DataID.TEST_DATA).data # gets requested data test_data2 = data.getData(DataID.TEST_DATA2).data self._publish(DataID.TEST_DATA3, ...) # pipes calculated data to next nodes \u2139 INFO: it is recommended not to use an already existing id in the publish method, otherwise the following nodes can no longer access the original dataset!","title":"Data processors"},{"location":"general/framework/getting-started/#end-nodes","text":"from driverless_framework.architecture.node_types import EndNode from driverless_framework.architecture.decorators.node_decorator import node from <path to id enum>.DataID import DataID class ENode(EndNode): def getName(self): return \"ENode\" @node([DataID.TEST_DATA]) # requests datasets def receive(self, data): test_data = data.getData(DataID.TEST_DATA).data # gets requested data \u2139 INFO: an endNode is comparable to a dataprocessor, except that you can't publish (pass on) data.","title":"End nodes"},{"location":"general/framework/getting-started/#manager","text":"import driverless_framework.architecture as a # Source(), EndNode() and Processor() has to be replaced manager = a.ManagerBuilder(Source(), EndNode()) \\ .addProcessorNode(Processor()) \\ .build() manager.start() \u2139 INFO: The manager merges the notes into a pipeline and executes it. The further behavior is primarily regulated in the source node.","title":"Manager"},{"location":"general/framework/getting-started/#special-functions","text":"","title":"Special functions"},{"location":"general/framework/getting-started/#data-recording","text":"import driverless_framework.architecture as a import driverless_framework.architecture.basic_nodes as b manager = a.ManagerBuilder(b.Player(\"<path>\", loop=True), b.Recorder(\"<path>\")) \\ .addProcessorNode(Processor()) \\ .build() manager.start() loop means that when the end of the recording is reached, it is played again from the beginning.","title":"Data recording"},{"location":"general/framework/getting-started/#global-variables","text":"self._publish(DataID.TEST_DATA3, ..., globalVariable=True) \u2139 INFO: Global variables are multithreading safe for calling in ros. The last value entered is always used. This allows data from nodes further down the pipeline to be sent to nodes further up the pipeline, which can retrieve the data like a normal dataset on the next pipeline run. Global variables are declared via an extra enum that inherits from IGlobalDataID.","title":"Global variables"},{"location":"general/framework/getting-started/#all-dataid","text":"It is possible by importing the BasicDataID enum and specifying it in the node anotation ( BasicDataID.ALL ) to get all datasets that have already been requested by a previous node. This is mainly intended for recording the data or a possible publication in the ros bridge. Usually this is only used in an EndNode.","title":"ALL DataID"},{"location":"general/framework/getting-started/#testing","text":"The framework offers a testcontainer for testing purposes. Here a processor node can be called like a normal function. The method expects a DataGroup with all required data sets as attribute. The output is also a DataGroup. group = DataGroup(0) group.addData(DataID.TEST_DATA, DataField(<data>)) group.addData(DataID.TEST_DATA2, DataField(<data>)) output = TestContainer(Processor()).test(group) # Processor is the Node to test out_data = output.getData(DataID.TEST_DATA3).data","title":"Testing"},{"location":"vehicle-navigation/Overview/","text":"Overview Architecture Nodes Data Sources Node Description Outputs PythonSource this module obtains its data directly from the simulator and publishes the requested data in the pipeline DataID.LIDAR_DATA, DataID.ODOMETRY_DATA, DataID.REFEREE_STATE RosSource this module obtains its data from the Ros Bridge and publishes the requested data in the pipeline DataID.LIDAR_DATA, DataID.ODOMETRY_DATA Processors Node Description Input Output ActionProcessor This module calculates the control data necessary to follow the driving profile DataID.TRACKPOINT_MAP, DataID.ODOMETRY_DATA, DataID.Z_ORIENTATION, DataID.VECTORCHAIN_FINISHED, DataID.MIN_CURVE_PATH, DataID.VELOCITY_PROFILE DataID.STEERING_DATA, DataID.THROTTLE_DATA, DataID.BRAKE_DATA DataConverter this module corrects the sensor position of the lidar and provisionally takes over the preclustering of the current data DataID.LIDAR_DATA, DataID.ODOMETRY_DATA DataID.Z_ORIENTATION, DataID.CONE_DATA MapBuilder this module creates a map based on the relative coordinates of the cones DataID.CONE_DATA, DataID.ODOMETRY_DATA, DataID.Z_ORIENTATION, DataID.REFEREE_STATE DataID.CONE_MAP PathPlanner this module calculates the racing line once after the first lap in a new thread DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED DataID.MIN_CURVE_PATH PathPlanningConverter This module deals with the conversion of the recorded map for further processing. This is only needed for testing purposes. DataID.CONE_MAP DataID.CONE_MAP RecordingSelector This module is used to select the data sets to be recorded DataID.LIDAR_DATA, DataID.ODOMETRY_DATA - TrackDetector this module deals with the recognition of the track and its boundaries DataID.CONE_MAP DataID.YELLOW_BORDER, DataID.BLUE_BORDER, DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED VelocityPlanner This module calculates a velocity profile for the corresponding track, under consideration of the car's limitations DataID.MIN_CURVE_PATH DataID.VELOCITY_PROFILE EndNodes Node Description Input PathVisualizer This module displays the conemap and the corresponding racing line with speed values DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED, DataID.CONE_MAP, DataID.VELOCITY_PROFILE PythonController This module transmits the control data to the simulator DataID.STEERING_DATA, DataID.THROTTLE_DATA,DataID.BRAKE_DATA","title":"Overview"},{"location":"vehicle-navigation/Overview/#overview","text":"","title":"Overview"},{"location":"vehicle-navigation/Overview/#architecture","text":"","title":"Architecture"},{"location":"vehicle-navigation/Overview/#nodes","text":"","title":"Nodes"},{"location":"vehicle-navigation/Overview/#data-sources","text":"Node Description Outputs PythonSource this module obtains its data directly from the simulator and publishes the requested data in the pipeline DataID.LIDAR_DATA, DataID.ODOMETRY_DATA, DataID.REFEREE_STATE RosSource this module obtains its data from the Ros Bridge and publishes the requested data in the pipeline DataID.LIDAR_DATA, DataID.ODOMETRY_DATA","title":"Data Sources"},{"location":"vehicle-navigation/Overview/#processors","text":"Node Description Input Output ActionProcessor This module calculates the control data necessary to follow the driving profile DataID.TRACKPOINT_MAP, DataID.ODOMETRY_DATA, DataID.Z_ORIENTATION, DataID.VECTORCHAIN_FINISHED, DataID.MIN_CURVE_PATH, DataID.VELOCITY_PROFILE DataID.STEERING_DATA, DataID.THROTTLE_DATA, DataID.BRAKE_DATA DataConverter this module corrects the sensor position of the lidar and provisionally takes over the preclustering of the current data DataID.LIDAR_DATA, DataID.ODOMETRY_DATA DataID.Z_ORIENTATION, DataID.CONE_DATA MapBuilder this module creates a map based on the relative coordinates of the cones DataID.CONE_DATA, DataID.ODOMETRY_DATA, DataID.Z_ORIENTATION, DataID.REFEREE_STATE DataID.CONE_MAP PathPlanner this module calculates the racing line once after the first lap in a new thread DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED DataID.MIN_CURVE_PATH PathPlanningConverter This module deals with the conversion of the recorded map for further processing. This is only needed for testing purposes. DataID.CONE_MAP DataID.CONE_MAP RecordingSelector This module is used to select the data sets to be recorded DataID.LIDAR_DATA, DataID.ODOMETRY_DATA - TrackDetector this module deals with the recognition of the track and its boundaries DataID.CONE_MAP DataID.YELLOW_BORDER, DataID.BLUE_BORDER, DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED VelocityPlanner This module calculates a velocity profile for the corresponding track, under consideration of the car's limitations DataID.MIN_CURVE_PATH DataID.VELOCITY_PROFILE","title":"Processors"},{"location":"vehicle-navigation/Overview/#endnodes","text":"Node Description Input PathVisualizer This module displays the conemap and the corresponding racing line with speed values DataID.TRACKPOINT_MAP, DataID.VECTORCHAIN_FINISHED, DataID.CONE_MAP, DataID.VELOCITY_PROFILE PythonController This module transmits the control data to the simulator DataID.STEERING_DATA, DataID.THROTTLE_DATA,DataID.BRAKE_DATA","title":"EndNodes"}]}